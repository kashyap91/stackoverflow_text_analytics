Last login: Tue Mar  5 23:48:04 on console
(base) Kashyaps-MacBook-Pro:~ kashyap$ cd VagrantCA675/
(base) Kashyaps-MacBook-Pro:VagrantCA675 kashyap$ vagrant ssh
Welcome to Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-142-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

8 packages can be updated.
0 updates are security updates.


Last login: Tue Mar  5 15:24:15 2019 from 10.0.2.2
vagrant@ubuntu-xenial:~$ cd /usr/lib
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ ls
mapper2.py  mapper4.py  reducer1.py  reducer3.py
mapper1.py          mapper3.py     reducer2.py

vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /usr/lib/mapreduce/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/05 23:55:22 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/05 23:55:22 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/05 23:55:22 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/05 23:55:23 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/05 23:55:23 INFO mapreduce.JobSubmitter: number of splits:1
19/03/05 23:55:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1429366136_0001
19/03/05 23:55:23 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/05 23:55:23 INFO mapreduce.Job: Running job: job_local1429366136_0001
19/03/05 23:55:23 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/05 23:55:23 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/05 23:55:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:23 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:23 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/05 23:55:23 INFO mapred.LocalJobRunner: Starting task: attempt_local1429366136_0001_m_000000_0
19/03/05 23:55:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:23 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:23 INFO mapred.MapTask: Processing split: file:/usr/lib/mapreduce/taskfilt.csv:0+204416
19/03/05 23:55:23 INFO mapred.MapTask: numReduceTasks: 1
19/03/05 23:55:23 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/05 23:55:23 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/05 23:55:23 INFO mapred.MapTask: soft limit at 83886080
19/03/05 23:55:23 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/05 23:55:23 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/05 23:55:23 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/05 23:55:23 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/05 23:55:23 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/05 23:55:23 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/05 23:55:23 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/05 23:55:23 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/05 23:55:23 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/05 23:55:23 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:23 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:23 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:23 INFO streaming.PipeMapRed: Records R/W=255/1
19/03/05 23:55:23 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:23 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:23 INFO mapred.LocalJobRunner: 
19/03/05 23:55:23 INFO mapred.MapTask: Starting flush of map output
19/03/05 23:55:23 INFO mapred.MapTask: Spilling map output
19/03/05 23:55:23 INFO mapred.MapTask: bufstart = 0; bufend = 793838; bufvoid = 104857600
19/03/05 23:55:23 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26149572(104598288); length = 64825/6553600
19/03/05 23:55:24 INFO mapred.MapTask: Finished spill 0
19/03/05 23:55:24 INFO mapred.Task: Task:attempt_local1429366136_0001_m_000000_0 is done. And is in the process of committing
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Records R/W=255/1
19/03/05 23:55:24 INFO mapred.Task: Task 'attempt_local1429366136_0001_m_000000_0' done.
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1429366136_0001_m_000000_0
19/03/05 23:55:24 INFO mapred.LocalJobRunner: map task executor complete.
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Starting task: attempt_local1429366136_0001_r_000000_0
19/03/05 23:55:24 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:24 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:24 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e085dee
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/05 23:55:24 INFO reduce.EventFetcher: attempt_local1429366136_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/05 23:55:24 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1429366136_0001_m_000000_0 decomp: 826322 len: 826326 to MEMORY
19/03/05 23:55:24 INFO reduce.InMemoryMapOutput: Read 826322 bytes from map-output for attempt_local1429366136_0001_m_000000_0
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 826322, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->826322
19/03/05 23:55:24 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/05 23:55:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/05 23:55:24 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 826279 bytes
19/03/05 23:55:24 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: Merged 1 segments, 826322 bytes to disk to satisfy reduce memory limit
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: Merging 1 files, 826326 bytes from disk
19/03/05 23:55:24 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/05 23:55:24 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 826279 bytes
19/03/05 23:55:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:24 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer1.py]
19/03/05 23:55:24 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/05 23:55:24 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/05 23:55:24 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:24 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:24 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:24 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:24 INFO streaming.PipeMapRed: Records R/W=2579/1
19/03/05 23:55:24 INFO streaming.PipeMapRed: R/W/S=10000/3367/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:24 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:24 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:24 INFO mapred.Task: Task:attempt_local1429366136_0001_r_000000_0 is done. And is in the process of committing
19/03/05 23:55:24 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:24 INFO mapred.Task: Task attempt_local1429366136_0001_r_000000_0 is allowed to commit now
19/03/05 23:55:24 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1429366136_0001_r_000000_0' to file:/tmp/mapreduce-output/_temporary/0/task_local1429366136_0001_r_000000
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Records R/W=2579/1 > reduce
19/03/05 23:55:24 INFO mapred.Task: Task 'attempt_local1429366136_0001_r_000000_0' done.
19/03/05 23:55:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1429366136_0001_r_000000_0
19/03/05 23:55:24 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/05 23:55:24 INFO mapreduce.Job: Job job_local1429366136_0001 running in uber mode : false
19/03/05 23:55:24 INFO mapreduce.Job:  map 100% reduce 100%
19/03/05 23:55:24 INFO mapreduce.Job: Job job_local1429366136_0001 completed successfully
19/03/05 23:55:24 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2332058
		FILE: Number of bytes written=4071401
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=433
		Map output records=16207
		Map output bytes=793838
		Map output materialized bytes=826326
		Input split bytes=88
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=826326
		Reduce input records=16207
		Reduce output records=6616
		Spilled Records=32414
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=445644800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=204416
	File Output Format Counters 
		Bytes Written=355149
19/03/05 23:55:24 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output/part-00000 -output /tmp/mapreduce-output2 -mapper /usr/lib/mapreduce/mapper2.py -reducer /usr/lib/mapreduce/reducer2.py
19/03/05 23:55:33 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/05 23:55:33 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/05 23:55:33 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/05 23:55:33 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/05 23:55:33 INFO mapreduce.JobSubmitter: number of splits:1
19/03/05 23:55:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1140733666_0001
19/03/05 23:55:33 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/05 23:55:33 INFO mapreduce.Job: Running job: job_local1140733666_0001
19/03/05 23:55:33 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/05 23:55:33 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/05 23:55:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:33 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/05 23:55:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1140733666_0001_m_000000_0
19/03/05 23:55:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:33 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output/part-00000:0+352385
19/03/05 23:55:33 INFO mapred.MapTask: numReduceTasks: 1
19/03/05 23:55:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/05 23:55:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/05 23:55:33 INFO mapred.MapTask: soft limit at 83886080
19/03/05 23:55:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/05 23:55:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/05 23:55:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/05 23:55:33 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper2.py]
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/05 23:55:33 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/05 23:55:33 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/05 23:55:33 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/05 23:55:33 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/05 23:55:33 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/05 23:55:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:33 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:33 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:33 INFO streaming.PipeMapRed: Records R/W=2373/1
19/03/05 23:55:34 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:34 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:34 INFO mapred.LocalJobRunner: 
19/03/05 23:55:34 INFO mapred.MapTask: Starting flush of map output
19/03/05 23:55:34 INFO mapred.MapTask: Spilling map output
19/03/05 23:55:34 INFO mapred.MapTask: bufstart = 0; bufend = 352395; bufvoid = 104857600
19/03/05 23:55:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/05 23:55:34 INFO mapred.MapTask: Finished spill 0
19/03/05 23:55:34 INFO mapred.Task: Task:attempt_local1140733666_0001_m_000000_0 is done. And is in the process of committing
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Records R/W=2373/1
19/03/05 23:55:34 INFO mapred.Task: Task 'attempt_local1140733666_0001_m_000000_0' done.
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1140733666_0001_m_000000_0
19/03/05 23:55:34 INFO mapred.LocalJobRunner: map task executor complete.
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1140733666_0001_r_000000_0
19/03/05 23:55:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:34 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1163e715
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/05 23:55:34 INFO reduce.EventFetcher: attempt_local1140733666_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/05 23:55:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1140733666_0001_m_000000_0 decomp: 365639 len: 365643 to MEMORY
19/03/05 23:55:34 INFO reduce.InMemoryMapOutput: Read 365639 bytes from map-output for attempt_local1140733666_0001_m_000000_0
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 365639, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->365639
19/03/05 23:55:34 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/05 23:55:34 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/05 23:55:34 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/05 23:55:34 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:34 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 365600 bytes
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: Merged 1 segments, 365639 bytes to disk to satisfy reduce memory limit
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: Merging 1 files, 365643 bytes from disk
19/03/05 23:55:34 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/05 23:55:34 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:34 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 365600 bytes
19/03/05 23:55:34 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:34 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer2.py]
19/03/05 23:55:34 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/05 23:55:34 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/05 23:55:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:34 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:34 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:34 INFO streaming.PipeMapRed: Records R/W=6616/1
19/03/05 23:55:34 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:34 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:34 INFO mapred.Task: Task:attempt_local1140733666_0001_r_000000_0 is done. And is in the process of committing
19/03/05 23:55:34 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:34 INFO mapred.Task: Task attempt_local1140733666_0001_r_000000_0 is allowed to commit now
19/03/05 23:55:34 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1140733666_0001_r_000000_0' to file:/tmp/mapreduce-output2/_temporary/0/task_local1140733666_0001_r_000000
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Records R/W=6616/1 > reduce
19/03/05 23:55:34 INFO mapred.Task: Task 'attempt_local1140733666_0001_r_000000_0' done.
19/03/05 23:55:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1140733666_0001_r_000000_0
19/03/05 23:55:34 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/05 23:55:34 INFO mapreduce.Job: Job job_local1140733666_0001 running in uber mode : false
19/03/05 23:55:34 INFO mapreduce.Job:  map 100% reduce 100%
19/03/05 23:55:34 INFO mapreduce.Job: Job job_local1140733666_0001 completed successfully
19/03/05 23:55:34 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1712168
		FILE: Number of bytes written=2729366
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=352395
		Map output materialized bytes=365643
		Input split bytes=89
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=365643
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=355153
	File Output Format Counters 
		Bytes Written=395153
19/03/05 23:55:34 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output2/part-00000 -output /tmp/mapreduce-output3 -mapper /usr/lib/mapreduce/mapper3.py -reducer /usr/lib/mapreduce/reducer3.py
19/03/05 23:55:43 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/05 23:55:43 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/05 23:55:43 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/05 23:55:43 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/05 23:55:43 INFO mapreduce.JobSubmitter: number of splits:1
19/03/05 23:55:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local612879221_0001
19/03/05 23:55:43 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/05 23:55:43 INFO mapreduce.Job: Running job: job_local612879221_0001
19/03/05 23:55:43 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/05 23:55:43 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/05 23:55:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:43 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Starting task: attempt_local612879221_0001_m_000000_0
19/03/05 23:55:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:43 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:43 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:43 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output2/part-00000:0+392081
19/03/05 23:55:43 INFO mapred.MapTask: numReduceTasks: 1
19/03/05 23:55:43 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/05 23:55:43 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/05 23:55:43 INFO mapred.MapTask: soft limit at 83886080
19/03/05 23:55:43 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/05 23:55:43 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/05 23:55:43 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/05 23:55:43 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper3.py]
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/05 23:55:43 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/05 23:55:43 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/05 23:55:43 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/05 23:55:43 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/05 23:55:43 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/05 23:55:43 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:43 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:43 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:43 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:43 INFO streaming.PipeMapRed: Records R/W=2265/1
19/03/05 23:55:43 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:43 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:43 INFO mapred.LocalJobRunner: 
19/03/05 23:55:43 INFO mapred.MapTask: Starting flush of map output
19/03/05 23:55:43 INFO mapred.MapTask: Spilling map output
19/03/05 23:55:43 INFO mapred.MapTask: bufstart = 0; bufend = 405321; bufvoid = 104857600
19/03/05 23:55:43 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/05 23:55:43 INFO mapred.MapTask: Finished spill 0
19/03/05 23:55:43 INFO mapred.Task: Task:attempt_local612879221_0001_m_000000_0 is done. And is in the process of committing
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Records R/W=2265/1
19/03/05 23:55:43 INFO mapred.Task: Task 'attempt_local612879221_0001_m_000000_0' done.
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Finishing task: attempt_local612879221_0001_m_000000_0
19/03/05 23:55:43 INFO mapred.LocalJobRunner: map task executor complete.
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/05 23:55:43 INFO mapred.LocalJobRunner: Starting task: attempt_local612879221_0001_r_000000_0
19/03/05 23:55:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:43 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:43 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:43 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1163e715
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/05 23:55:44 INFO reduce.EventFetcher: attempt_local612879221_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/05 23:55:44 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local612879221_0001_m_000000_0 decomp: 418564 len: 418568 to MEMORY
19/03/05 23:55:44 INFO reduce.InMemoryMapOutput: Read 418564 bytes from map-output for attempt_local612879221_0001_m_000000_0
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 418564, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->418564
19/03/05 23:55:44 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/05 23:55:44 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/05 23:55:44 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/05 23:55:44 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:44 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 418558 bytes
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: Merged 1 segments, 418564 bytes to disk to satisfy reduce memory limit
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: Merging 1 files, 418568 bytes from disk
19/03/05 23:55:44 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/05 23:55:44 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:44 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 418558 bytes
19/03/05 23:55:44 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:44 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer3.py]
19/03/05 23:55:44 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/05 23:55:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/05 23:55:44 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:44 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:44 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:44 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:44 INFO streaming.PipeMapRed: Records R/W=6616/1
19/03/05 23:55:44 INFO mapreduce.Job: Job job_local612879221_0001 running in uber mode : false
19/03/05 23:55:44 INFO mapreduce.Job:  map 100% reduce 0%
19/03/05 23:55:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:46 INFO mapred.Task: Task:attempt_local612879221_0001_r_000000_0 is done. And is in the process of committing
19/03/05 23:55:46 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:46 INFO mapred.Task: Task attempt_local612879221_0001_r_000000_0 is allowed to commit now
19/03/05 23:55:46 INFO output.FileOutputCommitter: Saved output of task 'attempt_local612879221_0001_r_000000_0' to file:/tmp/mapreduce-output3/_temporary/0/task_local612879221_0001_r_000000
19/03/05 23:55:46 INFO mapred.LocalJobRunner: Records R/W=6616/1 > reduce
19/03/05 23:55:46 INFO mapred.Task: Task 'attempt_local612879221_0001_r_000000_0' done.
19/03/05 23:55:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local612879221_0001_r_000000_0
19/03/05 23:55:46 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/05 23:55:47 INFO mapreduce.Job:  map 100% reduce 100%
19/03/05 23:55:47 INFO mapreduce.Job: Job job_local612879221_0001 completed successfully
19/03/05 23:55:47 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1898028
		FILE: Number of bytes written=2896879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=405321
		Map output materialized bytes=418568
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=418568
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=395157
	File Output Format Counters 
		Bytes Written=408489
19/03/05 23:55:47 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output3/part-00000 -output /tmp/mapreduce-output4 -mapper /usr/lib/mapreduce/mapper4.py
19/03/05 23:55:54 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/05 23:55:54 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/05 23:55:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/05 23:55:54 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/05 23:55:54 INFO mapreduce.JobSubmitter: number of splits:1
19/03/05 23:55:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1500238046_0001
19/03/05 23:55:54 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/05 23:55:54 INFO mapreduce.Job: Running job: job_local1500238046_0001
19/03/05 23:55:54 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/05 23:55:54 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/05 23:55:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:54 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:54 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/05 23:55:54 INFO mapred.LocalJobRunner: Starting task: attempt_local1500238046_0001_m_000000_0
19/03/05 23:55:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:54 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:54 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output3/part-00000:0+405313
19/03/05 23:55:54 INFO mapred.MapTask: numReduceTasks: 1
19/03/05 23:55:54 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/05 23:55:54 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/05 23:55:54 INFO mapred.MapTask: soft limit at 83886080
19/03/05 23:55:54 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/05 23:55:54 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/05 23:55:54 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/05 23:55:54 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper4.py]
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/05 23:55:54 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/05 23:55:54 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/05 23:55:54 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/05 23:55:54 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/05 23:55:54 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/05 23:55:54 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:54 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:54 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:54 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/05 23:55:55 INFO streaming.PipeMapRed: Records R/W=2278/1
19/03/05 23:55:55 INFO streaming.PipeMapRed: MRErrorThread done
19/03/05 23:55:55 INFO streaming.PipeMapRed: mapRedFinished
19/03/05 23:55:55 INFO mapred.LocalJobRunner: 
19/03/05 23:55:55 INFO mapred.MapTask: Starting flush of map output
19/03/05 23:55:55 INFO mapred.MapTask: Spilling map output
19/03/05 23:55:55 INFO mapred.MapTask: bufstart = 0; bufend = 457762; bufvoid = 104857600
19/03/05 23:55:55 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/05 23:55:55 INFO mapred.MapTask: Finished spill 0
19/03/05 23:55:55 INFO mapred.Task: Task:attempt_local1500238046_0001_m_000000_0 is done. And is in the process of committing
19/03/05 23:55:55 INFO mapred.LocalJobRunner: Records R/W=2278/1
19/03/05 23:55:55 INFO mapred.Task: Task 'attempt_local1500238046_0001_m_000000_0' done.
19/03/05 23:55:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1500238046_0001_m_000000_0
19/03/05 23:55:55 INFO mapred.LocalJobRunner: map task executor complete.
19/03/05 23:55:55 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/05 23:55:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1500238046_0001_r_000000_0
19/03/05 23:55:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/05 23:55:55 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/05 23:55:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/05 23:55:55 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d67ee20
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/05 23:55:55 INFO reduce.EventFetcher: attempt_local1500238046_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/05 23:55:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1500238046_0001_m_000000_0 decomp: 471061 len: 471065 to MEMORY
19/03/05 23:55:55 INFO reduce.InMemoryMapOutput: Read 471061 bytes from map-output for attempt_local1500238046_0001_m_000000_0
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 471061, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->471061
19/03/05 23:55:55 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/05 23:55:55 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/05 23:55:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/05 23:55:55 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 471018 bytes
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: Merged 1 segments, 471061 bytes to disk to satisfy reduce memory limit
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: Merging 1 files, 471065 bytes from disk
19/03/05 23:55:55 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/05 23:55:55 INFO mapred.Merger: Merging 1 sorted segments
19/03/05 23:55:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 471018 bytes
19/03/05 23:55:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:55 INFO mapred.Task: Task:attempt_local1500238046_0001_r_000000_0 is done. And is in the process of committing
19/03/05 23:55:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/05 23:55:55 INFO mapred.Task: Task attempt_local1500238046_0001_r_000000_0 is allowed to commit now
19/03/05 23:55:55 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1500238046_0001_r_000000_0' to file:/tmp/mapreduce-output4/_temporary/0/task_local1500238046_0001_r_000000
19/03/05 23:55:55 INFO mapred.LocalJobRunner: reduce > reduce
19/03/05 23:55:55 INFO mapred.Task: Task 'attempt_local1500238046_0001_r_000000_0' done.
19/03/05 23:55:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1500238046_0001_r_000000_0
19/03/05 23:55:55 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/05 23:55:55 INFO mapreduce.Job: Job job_local1500238046_0001 running in uber mode : false
19/03/05 23:55:55 INFO mapreduce.Job:  map 100% reduce 100%
19/03/05 23:55:55 INFO mapreduce.Job: Job job_local1500238046_0001 completed successfully
19/03/05 23:55:55 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2029694
		FILE: Number of bytes written=3108223
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=457762
		Map output materialized bytes=471065
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=471065
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=408493
	File Output Format Counters 
		Bytes Written=461282
19/03/05 23:55:55 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ ls
hadoop-vagrant      mapreduce-output   mapreduce-output3  ssh-qBDcmtV1fM
hsperfdata_vagrant  mapreduce-output2  mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ cd mapreduce-output4/
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ ls
part-00000  _SUCCESS
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ nano part-00000 
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ ls
part-00000  _SUCCESS
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ cd ..
vagrant@ubuntu-xenial:/tmp$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> use ca675;
OK
Time taken: 3.859 seconds
hive> hive -e 'select sum(Score) AS tot_Score, OwnerUserId from stkex_data where ownerUserId > 0 and ownerUserId IS NOT NULL group by OwnerUserId order by tot_Score DESC limit 10;' | sed 's/[\t]/,/g'  > /tmp/yourfile.csv
    > ;
NoViableAltException(24@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1300)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:208)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:77)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:70)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:468)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
FAILED: ParseException line 1:0 cannot recognize input near 'hive' '-' 'e'
hive> exit;
vagrant@ubuntu-xenial:/tmp$ hive -e 'select sum(Score) AS tot_Score, OwnerUserId from stkex_data where ownerUserId > 0 and ownerUserId IS NOT NULL group by OwnerUserId order by tot_Score DESC limit 10;' | sed 's/[\t]/,/g'  > /tmp/yourfile.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
FAILED: SemanticException [Error 10001]: Line 1:49 Table not found 'stkex_data'
vagrant@ubuntu-xenial:/tmp$ hive -e 'select sum(Score) AS tot_Score, OwnerUserId from ca675.stkex_data where ownerUserId > 0 and ownerUserId IS NOT NULL group by OwnerUserId order by tot_Score DESC limit 10;' | sed 's/[\t]/,/g'  > /tmp/yourfile.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = vagrant_20190306000440_8226c973-aa09-4baa-9274-8fbbad96351e
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:04:47,985 Stage-1 map = 0%,  reduce = 0%
2019-03-06 00:04:48,992 Stage-1 map = 100%,  reduce = 0%
2019-03-06 00:04:49,998 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local648495889_0001
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:04:51,202 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_local604358719_0002
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Stage-Stage-2:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 10.829 seconds, Fetched: 10 row(s)
vagrant@ubuntu-xenial:/tmp$ ls
derby.log       hsperfdata_vagrant  mapreduce-output3  vagrant
hadoop-vagrant  mapreduce-output    mapreduce-output4  yourfile.csv
hive            mapreduce-output2   ssh-qBDcmtV1fM
vagrant@ubuntu-xenial:/tmp$ nano yourfile.csv 
vagrant@ubuntu-xenial:/tmp$ rm yourfile.csv 
vagrant@ubuntu-xenial:/tmp$ hive -e 'select sum(Score) AS tot_Score, OwnerUserId from ca675.stkex_data where ownerUserId > 0 and ownerUserId IS NOT NULL group by OwnerUserId order by tot_Score DESC limit 10;' | sed 's/[\t]/,/g'  > /usr/lib/mapreduce/yourfile.csv
-bash: /usr/lib/mapreduce/yourfile.csv: Permission denied
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = vagrant_20190306000609_93524469-66fb-4213-95cd-fa3dd4a99347
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:06:16,519 Stage-1 map = 0%,  reduce = 0%
2019-03-06 00:06:17,538 Stage-1 map = 100%,  reduce = 0%
2019-03-06 00:06:18,541 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1825852669_0001
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:06:19,735 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_local1204212311_0002
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Stage-Stage-2:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
Time taken: 10.392 seconds, Fetched: 10 row(s)
vagrant@ubuntu-xenial:/tmp$ cd usr/lib/mapreduce
-bash: cd: usr/lib/mapreduce: No such file or directory
vagrant@ubuntu-xenial:/tmp$ cd usr
-bash: cd: usr: No such file or directory
vagrant@ubuntu-xenial:/tmp$ cd /usr/lib/mapreduce
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ ls
final commands.txt  mapper2.py  mapper4.py  reducer1.py  reducer3.py
mapper1.py          mapper3.py  README.md   reducer2.py  taskfilt.csv
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> useca675;
NoViableAltException(24@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1300)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:208)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:77)
	at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:70)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:468)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1317)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1457)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1237)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1227)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:184)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
FAILED: ParseException line 1:0 cannot recognize input near 'useca675' '<EOF>' '<EOF>'
Wed Mar 06 00:10:04 UTC 2019 Thread[8cb9f6ba-98d9-4059-bd87-67d900bca702 main,5,main] java.io.FileNotFoundException: derby.log (Permission denied)
----------------------------------------------------------------
Wed Mar 06 00:10:04 UTC 2019:
Booting Derby version The Apache Software Foundation - Apache Derby - 10.10.2.0 - (1582446): instance a816c00e-0169-5055-f395-0000063fe140 
on database directory /var/warehouse/metastore_db with class loader sun.misc.Launcher$AppClassLoader@3ecf72fd 
Loaded from file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/derby-10.10.2.0.jar
java.vendor=Oracle Corporation
java.runtime.version=1.8.0_201-b09
user.dir=/usr/lib/mapreduce
os.name=Linux
os.arch=amd64
os.version=4.4.0-142-generic
derby.system.home=null
Database Class Loader started - derby.database.classpath=''
hive> use ca675;
OK
Time taken: 0.117 seconds
hive> select * from stkex_data limit 1;
OK
53	716027
Time taken: 1.361 seconds, Fetched: 1 row(s)
hive> exit;
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ cd ..
vagrant@ubuntu-xenial:/usr/lib$ sudo scp kashyap@136.206.203.220:/Users/kashyap/Documents/Data/task5/tasknew.csv /usr/lib/hive
Password:
tasknew.csv                                                       100%  193MB  64.4MB/s   00:03    
vagrant@ubuntu-xenial:/usr/lib$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> use ca675;
Wed Mar 06 00:23:23 UTC 2019 Thread[03dacefb-efd6-4002-be48-2de2c2ae8819 main,5,main] java.io.FileNotFoundException: derby.log (Permission denied)
----------------------------------------------------------------
Wed Mar 06 00:23:23 UTC 2019:
Booting Derby version The Apache Software Foundation - Apache Derby - 10.10.2.0 - (1582446): instance a816c00e-0169-5062-25c3-000006d1c798 
on database directory /var/warehouse/metastore_db with class loader sun.misc.Launcher$AppClassLoader@3ecf72fd 
Loaded from file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/derby-10.10.2.0.jar
java.vendor=Oracle Corporation
java.runtime.version=1.8.0_201-b09
user.dir=/usr/lib
os.name=Linux
os.arch=amd64
os.version=4.4.0-142-generic
derby.system.home=null
Database Class Loader started - derby.database.classpath=''
OK
Time taken: 2.855 seconds
hive> drop table stkex_data;
OK
Time taken: 1.641 seconds
hive> CREATE TABLE IF NOT EXISTS stkex_data 
    > (OwnerUserId int, 
    > Body String)
    > ROW FORMAT DELIMITED
    > FIELDS TERMINATED BY ','
    > STORED AS TEXTFILE;
OK
Time taken: 0.625 seconds
hive> LOAD DATA LOCAL INPATH '/usr/lib/hive/tasknew.csv'OVERWRITE INTO TABLE ca675.stkex_data;
Loading data to table ca675.stkex_data
OK
Time taken: 0.911 seconds
hive> select count(*) stkex_data;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = vagrant_20190306002416_7d464fd9-39fc-4c61-a529-19a7aff4fdd4
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:24:18,287 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local266586376_0001
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
1
Time taken: 1.898 seconds, Fetched: 1 row(s)
hive> select * from stkex_data limit 1;
OK
716027	<p>Is it possible to create object without declaring class? Like in JavaScript  <code>obj = {a: '1'}; console.log(obj.a)</code></p> 
Time taken: 0.704 seconds, Fetched: 1 row(s)
hive> select * from stkex_data limit 3;
OK
716027	<p>Is it possible to create object without declaring class? Like in JavaScript  <code>obj = {a: '1'}; console.log(obj.a)</code></p> 
150978	"<p>Some legacy code relies on the platform's default charset for translations. For Windows and Linux installations in the ""western world"" I know what that means. But thinking about Russian or Asian platforms I am totally unsure what their platform's default charset is (just UTF-16?).</p>  <p>Therefore I would like to know what I would get when executing the following code line:</p>  <pre><code>System.out.println(""Default Charset="" + Charset.defaultCharset()); </code></pre>  <p><strong>Edit:</strong> I don't want to discuss the problems of charsets and their difference to unicode here. I just want to collect what operating systems will result in what specific charset. Please post only concrete values!</p> "
1063644	"<p>Hi I want to setup <code>AV</code> capture session to capture images with specific resolution (and  if possible  with specific quality) using  iphone camera. here's setupping <code>AV</code> session code</p>  <pre><code>// Create and configure a capture session and start it running - (void)setupCaptureSession  {     NSError *error = nil;      // Create the session     self.captureSession = [[AVCaptureSession alloc] init];      // Configure the session to produce lower resolution video frames  if your      // processing algorithm can cope. We'll specify medium quality for the     // chosen device.     captureSession.sessionPreset = AVCaptureSessionPresetMedium;      // Find a suitable AVCaptureDevice     NSArray *cameras=[AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];     AVCaptureDevice *device;     if ([UserDefaults camera]==UIImagePickerControllerCameraDeviceFront)     {         device =[cameras objectAtIndex:1];     }     else     {         device = [cameras objectAtIndex:0];     };      // Create a device input with the device and add it to the session.     AVCaptureDeviceInput *input = [AVCaptureDeviceInput deviceInputWithDevice:device error:&amp;error];     if (!input)     {         NSLog(@""PANIC: no media input"");     }     [captureSession addInput:input];      // Create a VideoDataOutput and add it to the session     AVCaptureVideoDataOutput *output = [[AVCaptureVideoDataOutput alloc] init];     [captureSession addOutput:output];     NSLog(@""connections: %@""  output.connections);      // Configure your output.     dispatch_queue_t queue = dispatch_queue_create(""myQueue""  NULL);     [output setSampleBufferDelegate:self queue:queue];     dispatch_release(queue);      // Specify the pixel format     output.videoSettings = [NSDictionary dictionaryWithObject:[NSNumber numberWithInt:kCVPixelFormatType_32BGRA] forKey:(id)kCVPixelBufferPixelFormatTypeKey];       // If you wish to cap the frame rate to a known value  such as 15 fps  set      // minFrameDuration.       // Assign session to an ivar.     [self setSession:captureSession];     [self.captureSession startRunning]; } </code></pre>  <p>and <code>setSession</code>:</p>  <pre><code>-(void)setSession:(AVCaptureSession *)session {     NSLog(@""setting session..."");     self.captureSession=session;     NSLog(@""setting camera view"");     self.previewLayer = [AVCaptureVideoPreviewLayer layerWithSession:session];     //UIView *aView = self.view;     CGRect videoRect = CGRectMake(20.0  20.0  280.0  255.0);     previewLayer.frame = videoRect; // Assume you want the preview layer to fill the view.     [previewLayer setBackgroundColor:[[UIColor grayColor] CGColor]];     [self.view.layer addSublayer:previewLayer];     //[aView.layer addSublayer:previewLayer]; } </code></pre>  <p>and output methods:</p>  <pre><code>// Delegate routine that is called when a sample buffer was written - (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer     fromConnection:(AVCaptureConnection *)connection {      //NSLog(@""captureOutput: didOutputSampleBufferFromConnection"");      // Create a UIImage from the sample buffer data     self.currentImage = [self imageFromSampleBuffer:sampleBuffer];      //&lt; Add your code here that uses the image &gt; }  // Create a UIImage from sample buffer data - (UIImage *) imageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer  {     //NSLog(@""imageFromSampleBuffer: called"");     // Get a CMSampleBuffer's Core Video image buffer for the media data     CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);      // Lock the base address of the pixel buffer     CVPixelBufferLockBaseAddress(imageBuffer  0);       // Get the number of bytes per row for the pixel buffer     void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);       // Get the number of bytes per row for the pixel buffer     size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);      // Get the pixel buffer width and height     size_t width = CVPixelBufferGetWidth(imageBuffer);      size_t height = CVPixelBufferGetHeight(imageBuffer);       // Create a device-dependent RGB color space     CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();       // Create a bitmap graphics context with the sample buffer data     CGContextRef context = CGBitmapContextCreate(baseAddress  width  height  8  bytesPerRow  colorSpace  kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst);      // Create a Quartz image from the pixel data in the bitmap graphics context     CGImageRef quartzImage = CGBitmapContextCreateImage(context);      // Unlock the pixel buffer     CVPixelBufferUnlockBaseAddress(imageBuffer 0);       // Free up the context and color space     CGContextRelease(context);      CGColorSpaceRelease(colorSpace);      // Create an image object from the Quartz image     UIImage *image = [UIImage imageWithCGImage:quartzImage];      // Release the Quartz image     CGImageRelease(quartzImage);      return (image); } </code></pre>  <p>Everything is quite standard. But where and what should I change to specify the resolution of captured image and it's quality. Help me please</p> "
Time taken: 0.122 seconds, Fetched: 3 row(s)
hive> select count(*) from stkex_data;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = vagrant_20190306002453_922dfceb-ffda-440c-971d-925e7cd6cbfa
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2019-03-06 00:24:55,169 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1416967028_0002
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
222898
Time taken: 1.686 seconds, Fetched: 1 row(s)
hive> exit;
vagrant@ubuntu-xenial:/usr/lib$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 87234 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/87234.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
Wed Mar 06 00:26:01 UTC 2019 Thread[813f5a12-33dd-418e-a4a6-85eb6f0a069d main,5,main] java.io.FileNotFoundException: derby.log (Permission denied)
----------------------------------------------------------------
Wed Mar 06 00:26:01 UTC 2019:
Booting Derby version The Apache Software Foundation - Apache Derby - 10.10.2.0 - (1582446): instance a816c00e-0169-5064-90c9-000007303438 
on database directory /var/warehouse/metastore_db with class loader sun.misc.Launcher$AppClassLoader@3ecf72fd 
Loaded from file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/derby-10.10.2.0.jar
java.vendor=Oracle Corporation
java.runtime.version=1.8.0_201-b09
user.dir=/usr/lib
os.name=Linux
os.arch=amd64
os.version=4.4.0-142-generic
derby.system.home=null
Database Class Loader started - derby.database.classpath=''
OK
Time taken: 5.044 seconds, Fetched: 3 row(s)
vagrant@ubuntu-xenial:/usr/lib$ cd /tmp
vagrant@ubuntu-xenial:/tmp$ ls
87234.csv  hadoop-vagrant  hsperfdata_vagrant  mapreduce-output2  mapreduce-output4  vagrant
derby.log  hive            mapreduce-output    mapreduce-output3  ssh-qBDcmtV1fM
vagrant@ubuntu-xenial:/tmp$ nano 87234.csv 
vagrant@ubuntu-xenial:/tmp$ nano 87234.csv 
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 4883 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/4883.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 4.917 seconds, Fetched: 35 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 9951 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/9951.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.01 seconds, Fetched: 26 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 6068 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/6068.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 4.911 seconds, Fetched: 39 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 89904 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/89904.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.746 seconds, Fetched: 13 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 51816 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/51816.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.389 seconds, Fetched: 67 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 49153 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/49153.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.006 seconds, Fetched: 89 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 95592 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/95592.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.124 seconds, Fetched: 7 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 39677 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/39677.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.279 seconds, Fetched: 100 row(s)
vagrant@ubuntu-xenial:/tmp$ hive -e 'select Body from ca675.stkex_data where ownerUserId = 63051 and ownerUserId IS NOT NULL;' | sed 's/[\t]/,/g'  > /tmp/63051.csv
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/lib/hive/apache-hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
OK
Time taken: 5.098 seconds, Fetched: 54 row(s)
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                mapreduce-output   mapreduce-output3  ssh-qBDcmtV1fM
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  mapreduce-output2  mapreduce-output4  vagrant
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /usr/lib/mapreduce/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/06 00:46:04 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:46:04 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:46:04 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:46:04 ERROR streaming.StreamJob: Error Launching job : Output directory file:/tmp/mapreduce-output already exists
Streaming Command Failed!
vagrant@ubuntu-xenial:/tmp$ rm mapreduce-output
rm: cannot remove 'mapreduce-output': Is a directory
vagrant@ubuntu-xenial:/tmp$ sudo rm mapreduce-output
rm: cannot remove 'mapreduce-output': Is a directory
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
rm: cannot remove 'mapreduce-output': No such file or directory
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
mapreduce-output2/ mapreduce-output3/ mapreduce-output4/ 
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
mapreduce-output2/ mapreduce-output3/ mapreduce-output4/ 
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                ssh-qBDcmtV1fM
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  vagrant
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /usr/lib/mapreduce/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/06 00:47:30 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:47:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:47:30 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:47:31 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:47:31 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:47:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2023332656_0001
19/03/06 00:47:31 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:47:31 INFO mapreduce.Job: Running job: job_local2023332656_0001
19/03/06 00:47:31 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:47:31 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:47:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Starting task: attempt_local2023332656_0001_m_000000_0
19/03/06 00:47:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:31 INFO mapred.MapTask: Processing split: file:/usr/lib/mapreduce/taskfilt.csv:0+204416
19/03/06 00:47:31 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:47:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:47:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:47:31 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:47:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:47:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:47:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:47:31 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:47:31 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:47:31 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:47:31 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:47:31 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: Records R/W=255/1
19/03/06 00:47:31 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:31 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:31 INFO mapred.LocalJobRunner: 
19/03/06 00:47:31 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:47:31 INFO mapred.MapTask: Spilling map output
19/03/06 00:47:31 INFO mapred.MapTask: bufstart = 0; bufend = 793838; bufvoid = 104857600
19/03/06 00:47:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26149572(104598288); length = 64825/6553600
19/03/06 00:47:31 INFO mapred.MapTask: Finished spill 0
19/03/06 00:47:31 INFO mapred.Task: Task:attempt_local2023332656_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Records R/W=255/1
19/03/06 00:47:31 INFO mapred.Task: Task 'attempt_local2023332656_0001_m_000000_0' done.
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local2023332656_0001_m_000000_0
19/03/06 00:47:31 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Starting task: attempt_local2023332656_0001_r_000000_0
19/03/06 00:47:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:31 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22c94209
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:47:31 INFO reduce.EventFetcher: attempt_local2023332656_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:47:31 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2023332656_0001_m_000000_0 decomp: 826322 len: 826326 to MEMORY
19/03/06 00:47:31 INFO reduce.InMemoryMapOutput: Read 826322 bytes from map-output for attempt_local2023332656_0001_m_000000_0
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 826322, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->826322
19/03/06 00:47:31 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:47:31 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:47:31 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:31 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 826279 bytes
19/03/06 00:47:31 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: Merged 1 segments, 826322 bytes to disk to satisfy reduce memory limit
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: Merging 1 files, 826326 bytes from disk
19/03/06 00:47:31 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:47:31 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:31 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 826279 bytes
19/03/06 00:47:31 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:31 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer1.py]
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:47:31 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: Records R/W=2579/1
19/03/06 00:47:31 INFO streaming.PipeMapRed: R/W/S=10000/2950/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:31 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:31 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:31 INFO mapred.Task: Task:attempt_local2023332656_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:47:31 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:31 INFO mapred.Task: Task attempt_local2023332656_0001_r_000000_0 is allowed to commit now
19/03/06 00:47:31 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2023332656_0001_r_000000_0' to file:/tmp/mapreduce-output/_temporary/0/task_local2023332656_0001_r_000000
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Records R/W=2579/1 > reduce
19/03/06 00:47:31 INFO mapred.Task: Task 'attempt_local2023332656_0001_r_000000_0' done.
19/03/06 00:47:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local2023332656_0001_r_000000_0
19/03/06 00:47:31 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:47:32 INFO mapreduce.Job: Job job_local2023332656_0001 running in uber mode : false
19/03/06 00:47:32 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:47:32 INFO mapreduce.Job: Job job_local2023332656_0001 completed successfully
19/03/06 00:47:32 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2332058
		FILE: Number of bytes written=4071401
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=433
		Map output records=16207
		Map output bytes=793838
		Map output materialized bytes=826326
		Input split bytes=88
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=826326
		Reduce input records=16207
		Reduce output records=6616
		Spilled Records=32414
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=204416
	File Output Format Counters 
		Bytes Written=355149
19/03/06 00:47:32 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output/part-00000 -output /tmp/mapreduce-output2 -mapper /usr/lib/mapreduce/mapper2.py -reducer /usr/lib/mapreduce/reducer2.py
19/03/06 00:47:39 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:47:39 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:47:39 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:47:39 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:47:39 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:47:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local444093713_0001
19/03/06 00:47:39 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:47:39 INFO mapreduce.Job: Running job: job_local444093713_0001
19/03/06 00:47:39 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:47:39 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:47:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Starting task: attempt_local444093713_0001_m_000000_0
19/03/06 00:47:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:40 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output/part-00000:0+352385
19/03/06 00:47:40 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:47:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:47:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:47:40 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:47:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:47:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:47:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:47:40 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper2.py]
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:47:40 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:47:40 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:47:40 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:47:40 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: Records R/W=2373/1
19/03/06 00:47:40 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:40 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:40 INFO mapred.LocalJobRunner: 
19/03/06 00:47:40 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:47:40 INFO mapred.MapTask: Spilling map output
19/03/06 00:47:40 INFO mapred.MapTask: bufstart = 0; bufend = 352395; bufvoid = 104857600
19/03/06 00:47:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/06 00:47:40 INFO mapred.MapTask: Finished spill 0
19/03/06 00:47:40 INFO mapred.Task: Task:attempt_local444093713_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Records R/W=2373/1
19/03/06 00:47:40 INFO mapred.Task: Task 'attempt_local444093713_0001_m_000000_0' done.
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local444093713_0001_m_000000_0
19/03/06 00:47:40 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Starting task: attempt_local444093713_0001_r_000000_0
19/03/06 00:47:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:40 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1163e715
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:47:40 INFO reduce.EventFetcher: attempt_local444093713_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:47:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local444093713_0001_m_000000_0 decomp: 365639 len: 365643 to MEMORY
19/03/06 00:47:40 INFO reduce.InMemoryMapOutput: Read 365639 bytes from map-output for attempt_local444093713_0001_m_000000_0
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 365639, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->365639
19/03/06 00:47:40 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:47:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:47:40 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:40 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 365600 bytes
19/03/06 00:47:40 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: Merged 1 segments, 365639 bytes to disk to satisfy reduce memory limit
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: Merging 1 files, 365643 bytes from disk
19/03/06 00:47:40 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:47:40 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:40 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 365600 bytes
19/03/06 00:47:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:40 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer2.py]
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:47:40 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:40 INFO streaming.PipeMapRed: Records R/W=6616/1
19/03/06 00:47:40 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:40 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:40 INFO mapred.Task: Task:attempt_local444093713_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:47:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:40 INFO mapred.Task: Task attempt_local444093713_0001_r_000000_0 is allowed to commit now
19/03/06 00:47:40 INFO output.FileOutputCommitter: Saved output of task 'attempt_local444093713_0001_r_000000_0' to file:/tmp/mapreduce-output2/_temporary/0/task_local444093713_0001_r_000000
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Records R/W=6616/1 > reduce
19/03/06 00:47:40 INFO mapred.Task: Task 'attempt_local444093713_0001_r_000000_0' done.
19/03/06 00:47:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local444093713_0001_r_000000_0
19/03/06 00:47:40 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:47:40 INFO mapreduce.Job: Job job_local444093713_0001 running in uber mode : false
19/03/06 00:47:40 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:47:40 INFO mapreduce.Job: Job job_local444093713_0001 completed successfully
19/03/06 00:47:41 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1712168
		FILE: Number of bytes written=2724762
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=352395
		Map output materialized bytes=365643
		Input split bytes=89
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=365643
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=355153
	File Output Format Counters 
		Bytes Written=395153
19/03/06 00:47:41 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output2/part-00000 -output /tmp/mapreduce-output3 -mapper /usr/lib/mapreduce/mapper3.py -reducer /usr/lib/mapreduce/reducer3.py
19/03/06 00:47:47 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:47:47 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:47:47 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:47:47 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:47:47 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:47:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1022100756_0001
19/03/06 00:47:47 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:47:47 INFO mapreduce.Job: Running job: job_local1022100756_0001
19/03/06 00:47:47 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:47:47 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:47:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1022100756_0001_m_000000_0
19/03/06 00:47:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:47 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output2/part-00000:0+392081
19/03/06 00:47:47 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:47:47 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:47:47 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:47:47 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:47:47 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:47:47 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:47:47 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:47:47 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper3.py]
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:47:47 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:47:47 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:47:47 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:47:47 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:47:47 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:47 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:47 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:47 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:47 INFO streaming.PipeMapRed: Records R/W=2421/1
19/03/06 00:47:47 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:47 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:47 INFO mapred.LocalJobRunner: 
19/03/06 00:47:47 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:47:47 INFO mapred.MapTask: Spilling map output
19/03/06 00:47:47 INFO mapred.MapTask: bufstart = 0; bufend = 405321; bufvoid = 104857600
19/03/06 00:47:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/06 00:47:47 INFO mapred.MapTask: Finished spill 0
19/03/06 00:47:47 INFO mapred.Task: Task:attempt_local1022100756_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Records R/W=2421/1
19/03/06 00:47:47 INFO mapred.Task: Task 'attempt_local1022100756_0001_m_000000_0' done.
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1022100756_0001_m_000000_0
19/03/06 00:47:47 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:47:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1022100756_0001_r_000000_0
19/03/06 00:47:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:47:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:47:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:47:47 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ffd1663
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:47:47 INFO reduce.EventFetcher: attempt_local1022100756_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:47:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1022100756_0001_m_000000_0 decomp: 418564 len: 418568 to MEMORY
19/03/06 00:47:47 INFO reduce.InMemoryMapOutput: Read 418564 bytes from map-output for attempt_local1022100756_0001_m_000000_0
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 418564, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->418564
19/03/06 00:47:47 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:47:47 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:47:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:47:47 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:47 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 418558 bytes
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: Merged 1 segments, 418564 bytes to disk to satisfy reduce memory limit
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: Merging 1 files, 418568 bytes from disk
19/03/06 00:47:47 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:47:47 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:47:47 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 418558 bytes
19/03/06 00:47:47 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:47 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer3.py]
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:47:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:47:48 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:48 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:48 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:48 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:47:48 INFO streaming.PipeMapRed: Records R/W=6616/1
19/03/06 00:47:48 INFO mapreduce.Job: Job job_local1022100756_0001 running in uber mode : false
19/03/06 00:47:48 INFO mapreduce.Job:  map 100% reduce 0%
19/03/06 00:47:50 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:47:50 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:47:50 INFO mapred.Task: Task:attempt_local1022100756_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:47:50 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:47:50 INFO mapred.Task: Task attempt_local1022100756_0001_r_000000_0 is allowed to commit now
19/03/06 00:47:50 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1022100756_0001_r_000000_0' to file:/tmp/mapreduce-output3/_temporary/0/task_local1022100756_0001_r_000000
19/03/06 00:47:50 INFO mapred.LocalJobRunner: Records R/W=6616/1 > reduce
19/03/06 00:47:50 INFO mapred.Task: Task 'attempt_local1022100756_0001_r_000000_0' done.
19/03/06 00:47:50 INFO mapred.LocalJobRunner: Finishing task: attempt_local1022100756_0001_r_000000_0
19/03/06 00:47:50 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:47:51 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:47:51 INFO mapreduce.Job: Job job_local1022100756_0001 completed successfully
19/03/06 00:47:51 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1898028
		FILE: Number of bytes written=2901483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=405321
		Map output materialized bytes=418568
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=418568
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=395157
	File Output Format Counters 
		Bytes Written=408489
19/03/06 00:47:51 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output3/part-00000 -output /tmp/mapreduce-output4 -mapper /usr/lib/mapreduce/mapper4.py
19/03/06 00:48:02 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:48:02 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:48:02 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:48:02 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:48:02 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:48:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local337457543_0001
19/03/06 00:48:02 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:48:02 INFO mapreduce.Job: Running job: job_local337457543_0001
19/03/06 00:48:02 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:48:02 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:48:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:48:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:48:02 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:48:02 INFO mapred.LocalJobRunner: Starting task: attempt_local337457543_0001_m_000000_0
19/03/06 00:48:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:48:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:48:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:48:02 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output3/part-00000:0+405313
19/03/06 00:48:02 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:48:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:48:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:48:02 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:48:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:48:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:48:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:48:02 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper4.py]
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:48:02 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:48:02 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:48:02 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:48:02 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:48:02 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:48:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:48:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:48:02 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:48:02 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:48:02 INFO streaming.PipeMapRed: Records R/W=2045/1
19/03/06 00:48:02 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:48:02 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:48:02 INFO mapred.LocalJobRunner: 
19/03/06 00:48:02 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:48:02 INFO mapred.MapTask: Spilling map output
19/03/06 00:48:02 INFO mapred.MapTask: bufstart = 0; bufend = 457762; bufvoid = 104857600
19/03/06 00:48:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26187936(104751744); length = 26461/6553600
19/03/06 00:48:03 INFO mapred.MapTask: Finished spill 0
19/03/06 00:48:03 INFO mapred.Task: Task:attempt_local337457543_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:48:03 INFO mapred.LocalJobRunner: Records R/W=2045/1
19/03/06 00:48:03 INFO mapred.Task: Task 'attempt_local337457543_0001_m_000000_0' done.
19/03/06 00:48:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local337457543_0001_m_000000_0
19/03/06 00:48:03 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:48:03 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:48:03 INFO mapred.LocalJobRunner: Starting task: attempt_local337457543_0001_r_000000_0
19/03/06 00:48:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:48:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:48:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:48:03 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4662ddc8
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:48:03 INFO reduce.EventFetcher: attempt_local337457543_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:48:03 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local337457543_0001_m_000000_0 decomp: 471061 len: 471065 to MEMORY
19/03/06 00:48:03 INFO reduce.InMemoryMapOutput: Read 471061 bytes from map-output for attempt_local337457543_0001_m_000000_0
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 471061, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->471061
19/03/06 00:48:03 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:48:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:48:03 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:48:03 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:48:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 471018 bytes
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: Merged 1 segments, 471061 bytes to disk to satisfy reduce memory limit
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: Merging 1 files, 471065 bytes from disk
19/03/06 00:48:03 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:48:03 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:48:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 471018 bytes
19/03/06 00:48:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:48:03 INFO mapred.Task: Task:attempt_local337457543_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:48:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:48:03 INFO mapred.Task: Task attempt_local337457543_0001_r_000000_0 is allowed to commit now
19/03/06 00:48:03 INFO output.FileOutputCommitter: Saved output of task 'attempt_local337457543_0001_r_000000_0' to file:/tmp/mapreduce-output4/_temporary/0/task_local337457543_0001_r_000000
19/03/06 00:48:03 INFO mapred.LocalJobRunner: reduce > reduce
19/03/06 00:48:03 INFO mapred.Task: Task 'attempt_local337457543_0001_r_000000_0' done.
19/03/06 00:48:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local337457543_0001_r_000000_0
19/03/06 00:48:03 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:48:03 INFO mapreduce.Job: Job job_local337457543_0001 running in uber mode : false
19/03/06 00:48:03 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:48:03 INFO mapreduce.Job: Job job_local337457543_0001 completed successfully
19/03/06 00:48:03 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2029694
		FILE: Number of bytes written=3103643
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6616
		Map output records=6616
		Map output bytes=457762
		Map output materialized bytes=471065
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6616
		Reduce shuffle bytes=471065
		Reduce input records=6616
		Reduce output records=6616
		Spilled Records=13232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=408493
	File Output Format Counters 
		Bytes Written=461282
19/03/06 00:48:03 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                mapreduce-output   mapreduce-output3  ssh-qBDcmtV1fM
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  mapreduce-output2  mapreduce-output4  vagrant
vagrant@ubuntu-xenial:/tmp$ cd mapreduce-output4
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ ls
part-00000  _SUCCESS
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ nano part-00000 
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ rm -r mapreduce-output
rm: cannot remove 'mapreduce-output': No such file or directory
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ rm -r mapreduce-output2
rm: cannot remove 'mapreduce-output2': No such file or directory
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ rm -r mapreduce-output3
rm: cannot remove 'mapreduce-output3': No such file or directory
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ cd ..
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                mapreduce-output4  vagrant
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  ssh-qBDcmtV1fM
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                ssh-qBDcmtV1fM
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  vagrant
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/06 00:49:45 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:49:45 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:49:45 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:49:45 INFO mapred.FileInputFormat: Total input files to process : 10
19/03/06 00:49:45 INFO mapreduce.JobSubmitter: number of splits:10
19/03/06 00:49:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1469189390_0001
19/03/06 00:49:45 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:49:45 INFO mapreduce.Job: Running job: job_local1469189390_0001
19/03/06 00:49:45 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:49:45 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:49:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:45 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000000_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/39677.csv:0+48303
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:49:46 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:49:46 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:49:46 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:49:46 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:49:46 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=100/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 118960; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26200032(104800128); length = 14365/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=100/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000000_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000000_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000001_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/49153.csv:0+46318
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=89/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 118539; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26199260(104797040); length = 15137/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000001_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=89/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000001_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000001_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000002_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/51816.csv:0+26002
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=67/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 71084; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205116(104820464); length = 9281/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000002_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=67/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000002_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000002_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000003_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/6068.csv:0+20541
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=39/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 48601; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26208160(104832640); length = 6237/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000003_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=39/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000003_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000003_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000004_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/9951.csv:0+14476
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=26/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 37335; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209360(104837440); length = 5037/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000004_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=26/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000004_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000004_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000005_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/63051.csv:0+13458
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=54/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 36991; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209564(104838256); length = 4833/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000005_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=54/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000005_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000005_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000006_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/95592.csv:0+11463
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: Records R/W=7/1
19/03/06 00:49:46 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:46 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:46 INFO mapred.LocalJobRunner: 
19/03/06 00:49:46 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:46 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufend = 27992; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26211112(104844448); length = 3285/6553600
19/03/06 00:49:46 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:46 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000006_0 is done. And is in the process of committing
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Records R/W=7/1
19/03/06 00:49:46 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000006_0' done.
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000006_0
19/03/06 00:49:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000007_0
19/03/06 00:49:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:46 INFO mapred.MapTask: Processing split: file:/tmp/4883.csv:0+9406
19/03/06 00:49:46 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:46 INFO mapreduce.Job: Job job_local1469189390_0001 running in uber mode : false
19/03/06 00:49:46 INFO mapreduce.Job:  map 100% reduce 0%
19/03/06 00:49:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:46 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:46 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:46 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: Records R/W=35/1
19/03/06 00:49:47 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:47 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 
19/03/06 00:49:47 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:47 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:47 INFO mapred.MapTask: bufstart = 0; bufend = 25088; bufvoid = 104857600
19/03/06 00:49:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210964(104843856); length = 3433/6553600
19/03/06 00:49:47 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:47 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000007_0 is done. And is in the process of committing
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Records R/W=35/1
19/03/06 00:49:47 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000007_0' done.
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000007_0
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000008_0
19/03/06 00:49:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:47 INFO mapred.MapTask: Processing split: file:/tmp/89904.csv:0+5081
19/03/06 00:49:47 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:47 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:47 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:47 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:47 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:47 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:47 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:47 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: Records R/W=13/1
19/03/06 00:49:47 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:47 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 
19/03/06 00:49:47 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:47 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:47 INFO mapred.MapTask: bufstart = 0; bufend = 12580; bufvoid = 104857600
19/03/06 00:49:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212844(104851376); length = 1553/6553600
19/03/06 00:49:47 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:47 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000008_0 is done. And is in the process of committing
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Records R/W=13/1
19/03/06 00:49:47 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000008_0' done.
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000008_0
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_m_000009_0
19/03/06 00:49:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:47 INFO mapred.MapTask: Processing split: file:/tmp/87234.csv:0+4490
19/03/06 00:49:47 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:47 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:47 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:47 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:47 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:47 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:47 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:47 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: Records R/W=3/1
19/03/06 00:49:47 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:47 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 
19/03/06 00:49:47 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:47 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:47 INFO mapred.MapTask: bufstart = 0; bufend = 12546; bufvoid = 104857600
19/03/06 00:49:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212760(104851040); length = 1637/6553600
19/03/06 00:49:47 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:47 INFO mapred.Task: Task:attempt_local1469189390_0001_m_000009_0 is done. And is in the process of committing
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Records R/W=3/1
19/03/06 00:49:47 INFO mapred.Task: Task 'attempt_local1469189390_0001_m_000009_0' done.
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_m_000009_0
19/03/06 00:49:47 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1469189390_0001_r_000000_0
19/03/06 00:49:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:47 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b8733fd
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=368836608, maxSingleShuffleLimit=92209152, mergeThreshold=243432176, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:49:47 INFO reduce.EventFetcher: attempt_local1469189390_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000008_0 decomp: 13360 len: 13364 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 13360 bytes from map-output for attempt_local1469189390_0001_m_000008_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13360, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13360
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000001_0 decomp: 126115 len: 126119 to MEMORY
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 126115 bytes from map-output for attempt_local1469189390_0001_m_000001_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 126115, inMemoryMapOutputs.size() -> 2, commitMemory -> 13360, usedMemory ->139475
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000002_0 decomp: 75730 len: 75734 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 75730 bytes from map-output for attempt_local1469189390_0001_m_000002_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 75730, inMemoryMapOutputs.size() -> 3, commitMemory -> 139475, usedMemory ->215205
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000005_0 decomp: 39411 len: 39415 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 39411 bytes from map-output for attempt_local1469189390_0001_m_000005_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39411, inMemoryMapOutputs.size() -> 4, commitMemory -> 215205, usedMemory ->254616
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000000_0 decomp: 126155 len: 126159 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 126155 bytes from map-output for attempt_local1469189390_0001_m_000000_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 126155, inMemoryMapOutputs.size() -> 5, commitMemory -> 254616, usedMemory ->380771
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000003_0 decomp: 51726 len: 51730 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 51726 bytes from map-output for attempt_local1469189390_0001_m_000003_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51726, inMemoryMapOutputs.size() -> 6, commitMemory -> 380771, usedMemory ->432497
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000006_0 decomp: 29638 len: 29642 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 29638 bytes from map-output for attempt_local1469189390_0001_m_000006_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29638, inMemoryMapOutputs.size() -> 7, commitMemory -> 432497, usedMemory ->462135
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000009_0 decomp: 13372 len: 13376 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 13372 bytes from map-output for attempt_local1469189390_0001_m_000009_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13372, inMemoryMapOutputs.size() -> 8, commitMemory -> 462135, usedMemory ->475507
19/03/06 00:49:47 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000004_0 decomp: 39859 len: 39863 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 39859 bytes from map-output for attempt_local1469189390_0001_m_000004_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39859, inMemoryMapOutputs.size() -> 9, commitMemory -> 475507, usedMemory ->515366
19/03/06 00:49:47 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1469189390_0001_m_000007_0 decomp: 26808 len: 26812 to MEMORY
19/03/06 00:49:47 INFO reduce.InMemoryMapOutput: Read 26808 bytes from map-output for attempt_local1469189390_0001_m_000007_0
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 26808, inMemoryMapOutputs.size() -> 10, commitMemory -> 515366, usedMemory ->542174
19/03/06 00:49:47 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:49:47 INFO mapred.Merger: Merging 10 sorted segments
19/03/06 00:49:47 INFO mapred.Merger: Down to the last merge-pass, with 10 segments left of total size: 541933 bytes
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: Merged 10 segments, 542174 bytes to disk to satisfy reduce memory limit
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: Merging 1 files, 542160 bytes from disk
19/03/06 00:49:47 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:49:47 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:49:47 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 542130 bytes
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 00:49:47 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer1.py]
19/03/06 00:49:47 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:49:47 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: Records R/W=3947/1
19/03/06 00:49:47 INFO streaming.PipeMapRed: R/W/S=10000/3080/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:47 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:47 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:47 INFO mapred.Task: Task:attempt_local1469189390_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:49:47 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 00:49:47 INFO mapred.Task: Task attempt_local1469189390_0001_r_000000_0 is allowed to commit now
19/03/06 00:49:47 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1469189390_0001_r_000000_0' to file:/tmp/mapreduce-output/_temporary/0/task_local1469189390_0001_r_000000
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Records R/W=3947/1 > reduce
19/03/06 00:49:47 INFO mapred.Task: Task 'attempt_local1469189390_0001_r_000000_0' done.
19/03/06 00:49:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1469189390_0001_r_000000_0
19/03/06 00:49:47 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:49:47 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:49:47 INFO mapreduce.Job: Job job_local1469189390_0001 completed successfully
19/03/06 00:49:48 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=4312117
		FILE: Number of bytes written=12251328
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=433
		Map output records=16207
		Map output bytes=509716
		Map output materialized bytes=542214
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=9131
		Reduce shuffle bytes=542214
		Reduce input records=16207
		Reduce output records=9131
		Spilled Records=32414
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=103
		Total committed heap usage (bytes)=4708106240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=199538
	File Output Format Counters 
		Bytes Written=308170
19/03/06 00:49:48 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output/part-00000 -output /tmp/mapreduce-output2 -mapper /usr/lib/mapreduce/mapper2.py -reducer /usr/lib/mapreduce/reducer2.py
19/03/06 00:49:52 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:49:52 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:49:52 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:49:52 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:49:52 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:49:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local197403027_0001
19/03/06 00:49:53 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:49:53 INFO mapreduce.Job: Running job: job_local197403027_0001
19/03/06 00:49:53 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:49:53 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:49:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Starting task: attempt_local197403027_0001_m_000000_0
19/03/06 00:49:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:53 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output/part-00000:0+305770
19/03/06 00:49:53 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:53 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:53 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:53 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:53 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:53 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:53 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:53 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper2.py]
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:49:53 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:49:53 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:49:53 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:49:53 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: Records R/W=3855/1
19/03/06 00:49:53 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:53 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:53 INFO mapred.LocalJobRunner: 
19/03/06 00:49:53 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:53 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:53 INFO mapred.MapTask: bufstart = 0; bufend = 305780; bufvoid = 104857600
19/03/06 00:49:53 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26177876(104711504); length = 36521/6553600
19/03/06 00:49:53 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:53 INFO mapred.Task: Task:attempt_local197403027_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Records R/W=3855/1
19/03/06 00:49:53 INFO mapred.Task: Task 'attempt_local197403027_0001_m_000000_0' done.
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local197403027_0001_m_000000_0
19/03/06 00:49:53 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Starting task: attempt_local197403027_0001_r_000000_0
19/03/06 00:49:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:53 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@331a4c37
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:49:53 INFO reduce.EventFetcher: attempt_local197403027_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:49:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local197403027_0001_m_000000_0 decomp: 324054 len: 324058 to MEMORY
19/03/06 00:49:53 INFO reduce.InMemoryMapOutput: Read 324054 bytes from map-output for attempt_local197403027_0001_m_000000_0
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 324054, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->324054
19/03/06 00:49:53 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:49:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:49:53 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:49:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 324032 bytes
19/03/06 00:49:53 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: Merged 1 segments, 324054 bytes to disk to satisfy reduce memory limit
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: Merging 1 files, 324058 bytes from disk
19/03/06 00:49:53 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:49:53 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:49:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 324032 bytes
19/03/06 00:49:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:49:53 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer2.py]
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:49:53 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:53 INFO streaming.PipeMapRed: Records R/W=9131/1
19/03/06 00:49:53 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:53 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:53 INFO mapred.Task: Task:attempt_local197403027_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:49:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:49:53 INFO mapred.Task: Task attempt_local197403027_0001_r_000000_0 is allowed to commit now
19/03/06 00:49:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local197403027_0001_r_000000_0' to file:/tmp/mapreduce-output2/_temporary/0/task_local197403027_0001_r_000000
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Records R/W=9131/1 > reduce
19/03/06 00:49:53 INFO mapred.Task: Task 'attempt_local197403027_0001_r_000000_0' done.
19/03/06 00:49:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local197403027_0001_r_000000_0
19/03/06 00:49:53 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:49:54 INFO mapreduce.Job: Job job_local197403027_0001 running in uber mode : false
19/03/06 00:49:54 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:49:54 INFO mapreduce.Job: Job job_local197403027_0001 completed successfully
19/03/06 00:49:54 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1535040
		FILE: Number of bytes written=2557431
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9131
		Map output records=9131
		Map output bytes=305780
		Map output materialized bytes=324058
		Input split bytes=89
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=324058
		Reduce input records=9131
		Reduce output records=9131
		Spilled Records=18262
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=308174
	File Output Format Counters 
		Bytes Written=352577
19/03/06 00:49:54 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output2/part-00000 -output /tmp/mapreduce-output3 -mapper /usr/lib/mapreduce/mapper3.py -reducer /usr/lib/mapreduce/reducer3.py
19/03/06 00:49:58 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:49:58 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:49:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:49:59 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:49:59 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:49:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1380279992_0001
19/03/06 00:49:59 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:49:59 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:49:59 INFO mapreduce.Job: Running job: job_local1380279992_0001
19/03/06 00:49:59 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:49:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1380279992_0001_m_000000_0
19/03/06 00:49:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:59 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output2/part-00000:0+349833
19/03/06 00:49:59 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:49:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:49:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:49:59 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:49:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:49:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:49:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:49:59 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper3.py]
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:49:59 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:49:59 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:49:59 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:49:59 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: Records R/W=3330/1
19/03/06 00:49:59 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:49:59 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:49:59 INFO mapred.LocalJobRunner: 
19/03/06 00:49:59 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:49:59 INFO mapred.MapTask: Spilling map output
19/03/06 00:49:59 INFO mapred.MapTask: bufstart = 0; bufend = 368103; bufvoid = 104857600
19/03/06 00:49:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26177876(104711504); length = 36521/6553600
19/03/06 00:49:59 INFO mapred.MapTask: Finished spill 0
19/03/06 00:49:59 INFO mapred.Task: Task:attempt_local1380279992_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Records R/W=3330/1
19/03/06 00:49:59 INFO mapred.Task: Task 'attempt_local1380279992_0001_m_000000_0' done.
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1380279992_0001_m_000000_0
19/03/06 00:49:59 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:49:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1380279992_0001_r_000000_0
19/03/06 00:49:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:49:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:49:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:49:59 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@21b24ace
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:49:59 INFO reduce.EventFetcher: attempt_local1380279992_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:49:59 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1380279992_0001_m_000000_0 decomp: 386376 len: 386380 to MEMORY
19/03/06 00:49:59 INFO reduce.InMemoryMapOutput: Read 386376 bytes from map-output for attempt_local1380279992_0001_m_000000_0
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 386376, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->386376
19/03/06 00:49:59 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:49:59 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:49:59 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:49:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 386370 bytes
19/03/06 00:49:59 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: Merged 1 segments, 386376 bytes to disk to satisfy reduce memory limit
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: Merging 1 files, 386380 bytes from disk
19/03/06 00:49:59 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:49:59 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:49:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 386370 bytes
19/03/06 00:49:59 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:49:59 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer3.py]
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 00:49:59 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:49:59 INFO streaming.PipeMapRed: Records R/W=9131/1
19/03/06 00:50:00 INFO mapreduce.Job: Job job_local1380279992_0001 running in uber mode : false
19/03/06 00:50:00 INFO mapreduce.Job:  map 100% reduce 0%
19/03/06 00:50:02 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:50:02 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:50:02 INFO mapred.Task: Task:attempt_local1380279992_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:50:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:50:02 INFO mapred.Task: Task attempt_local1380279992_0001_r_000000_0 is allowed to commit now
19/03/06 00:50:02 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1380279992_0001_r_000000_0' to file:/tmp/mapreduce-output3/_temporary/0/task_local1380279992_0001_r_000000
19/03/06 00:50:02 INFO mapred.LocalJobRunner: Records R/W=9131/1 > reduce
19/03/06 00:50:02 INFO mapred.Task: Task 'attempt_local1380279992_0001_r_000000_0' done.
19/03/06 00:50:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1380279992_0001_r_000000_0
19/03/06 00:50:02 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:50:03 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:50:03 INFO mapreduce.Job: Job job_local1380279992_0001 completed successfully
19/03/06 00:50:03 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1748500
		FILE: Number of bytes written=2663656
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9131
		Map output records=9131
		Map output bytes=368103
		Map output materialized bytes=386380
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6238
		Reduce shuffle bytes=386380
		Reduce input records=9131
		Reduce output records=6238
		Spilled Records=18262
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=352581
	File Output Format Counters 
		Bytes Written=267226
19/03/06 00:50:03 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output3/part-00000 -output /tmp/mapreduce-output4 -mapper /usr/lib/mapreduce/mapper4.py
19/03/06 00:50:05 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:50:05 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:50:05 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:50:06 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 00:50:06 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 00:50:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local403968179_0001
19/03/06 00:50:06 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 00:50:06 INFO mapreduce.Job: Running job: job_local403968179_0001
19/03/06 00:50:06 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 00:50:06 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 00:50:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:50:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Starting task: attempt_local403968179_0001_m_000000_0
19/03/06 00:50:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:50:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:50:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:50:06 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output3/part-00000:0+265146
19/03/06 00:50:06 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 00:50:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 00:50:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 00:50:06 INFO mapred.MapTask: soft limit at 83886080
19/03/06 00:50:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 00:50:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 00:50:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 00:50:06 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper4.py]
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 00:50:06 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 00:50:06 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 00:50:06 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 00:50:06 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 00:50:06 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 00:50:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:50:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:50:06 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:50:06 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 00:50:06 INFO streaming.PipeMapRed: Records R/W=3676/1
19/03/06 00:50:06 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 00:50:06 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 00:50:06 INFO mapred.LocalJobRunner: 
19/03/06 00:50:06 INFO mapred.MapTask: Starting flush of map output
19/03/06 00:50:06 INFO mapred.MapTask: Spilling map output
19/03/06 00:50:06 INFO mapred.MapTask: bufstart = 0; bufend = 320489; bufvoid = 104857600
19/03/06 00:50:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26189448(104757792); length = 24949/6553600
19/03/06 00:50:06 INFO mapred.MapTask: Finished spill 0
19/03/06 00:50:06 INFO mapred.Task: Task:attempt_local403968179_0001_m_000000_0 is done. And is in the process of committing
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Records R/W=3676/1
19/03/06 00:50:06 INFO mapred.Task: Task 'attempt_local403968179_0001_m_000000_0' done.
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local403968179_0001_m_000000_0
19/03/06 00:50:06 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Starting task: attempt_local403968179_0001_r_000000_0
19/03/06 00:50:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 00:50:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 00:50:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 00:50:06 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6d125fe7
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 00:50:06 INFO reduce.EventFetcher: attempt_local403968179_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 00:50:06 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local403968179_0001_m_000000_0 decomp: 332991 len: 332995 to MEMORY
19/03/06 00:50:06 INFO reduce.InMemoryMapOutput: Read 332991 bytes from map-output for attempt_local403968179_0001_m_000000_0
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 332991, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->332991
19/03/06 00:50:06 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 00:50:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 00:50:06 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:50:06 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 332965 bytes
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: Merged 1 segments, 332991 bytes to disk to satisfy reduce memory limit
19/03/06 00:50:06 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: Merging 1 files, 332995 bytes from disk
19/03/06 00:50:06 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 00:50:06 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 00:50:06 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 332965 bytes
19/03/06 00:50:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:50:06 INFO mapred.Task: Task:attempt_local403968179_0001_r_000000_0 is done. And is in the process of committing
19/03/06 00:50:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 00:50:06 INFO mapred.Task: Task attempt_local403968179_0001_r_000000_0 is allowed to commit now
19/03/06 00:50:06 INFO output.FileOutputCommitter: Saved output of task 'attempt_local403968179_0001_r_000000_0' to file:/tmp/mapreduce-output4/_temporary/0/task_local403968179_0001_r_000000
19/03/06 00:50:06 INFO mapred.LocalJobRunner: reduce > reduce
19/03/06 00:50:06 INFO mapred.Task: Task 'attempt_local403968179_0001_r_000000_0' done.
19/03/06 00:50:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local403968179_0001_r_000000_0
19/03/06 00:50:06 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 00:50:07 INFO mapreduce.Job: Job job_local403968179_0001 running in uber mode : false
19/03/06 00:50:07 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 00:50:07 INFO mapreduce.Job: Job job_local403968179_0001 completed successfully
19/03/06 00:50:07 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1471028
		FILE: Number of bytes written=2551131
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6238
		Map output records=6238
		Map output bytes=320489
		Map output materialized bytes=332995
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6238
		Reduce shuffle bytes=332995
		Reduce input records=6238
		Reduce output records=6238
		Spilled Records=12476
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=267230
	File Output Format Counters 
		Bytes Written=322980
19/03/06 00:50:07 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ cd mapreduce-output4
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ la
part-00000  .part-00000.crc  _SUCCESS  ._SUCCESS.crc
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ ls
part-00000  _SUCCESS
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ nano part-00000 
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ cd /usr/lib/mapreduce
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ ls
final commands.txt  mapper1.py  mapper2.py  mapper3.py  mapper4.py  README.md  reducer1.py  reducer2.py  reducer3.py  taskfilt.csv
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ rm mapper1
rm: cannot remove 'mapper1': No such file or directory
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ rm mapper1.py 
rm: remove write-protected regular file 'mapper1.py'? y
rm: cannot remove 'mapper1.py': Permission denied
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ sudo rm mapper1.py 
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ sudo scp kashyap@136.206.203.220:/Users/kashyap/Documents/tf/mapper1.py /usr/lib/mapreduce
Password:
mapper1.py                                                                                                      100% 1724     1.7KB/s   00:00    
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/06 00:59:47 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 00:59:47 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 00:59:47 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 00:59:47 ERROR streaming.StreamJob: Error Launching job : Output directory file:/tmp/mapreduce-output already exists
Streaming Command Failed!
vagrant@ubuntu-xenial:/usr/lib/mapreduce$ cd /tmp
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ rm -r mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ ls
39677.csv  49153.csv  6068.csv   87234.csv  95592.csv  derby.log       hive                ssh-qBDcmtV1fM
4883.csv   51816.csv  63051.csv  89904.csv  9951.csv   hadoop-vagrant  hsperfdata_vagrant  vagrant
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/*.csv -output /tmp/mapreduce-output -mapper /usr/lib/mapreduce/mapper1.py -reducer /usr/lib/mapreduce/reducer1.py
19/03/06 01:00:16 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 01:00:16 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 01:00:16 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 01:00:16 INFO mapred.FileInputFormat: Total input files to process : 10
19/03/06 01:00:16 INFO mapreduce.JobSubmitter: number of splits:10
19/03/06 01:00:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local860817634_0001
19/03/06 01:00:17 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 01:00:17 INFO mapreduce.Job: Running job: job_local860817634_0001
19/03/06 01:00:17 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 01:00:17 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000000_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/39677.csv:0+48303
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 01:00:17 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 01:00:17 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 01:00:17 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 01:00:17 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 01:00:17 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=100/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 115432; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26200620(104802480); length = 13777/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000000_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=100/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000000_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000000_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000001_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/49153.csv:0+46318
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=89/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 114363; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26199956(104799824); length = 14441/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000001_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=89/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000001_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000001_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000002_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/51816.csv:0+26002
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=67/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 65900; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205980(104823920); length = 8417/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000002_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=67/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000002_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000002_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000003_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/6068.csv:0+20541
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=39/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 47796; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26208300(104833200); length = 6097/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000003_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=39/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000003_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000003_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000004_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/9951.csv:0+14476
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=26/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 36461; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209512(104838048); length = 4885/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000004_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=26/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000004_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000004_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000005_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/63051.csv:0+13458
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=54/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 36319; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209676(104838704); length = 4721/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000005_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=54/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000005_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000005_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000006_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/95592.csv:0+11463
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=7/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 27704; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26211160(104844640); length = 3237/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000006_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=7/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000006_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000006_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000007_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/4883.csv:0+9406
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=35/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 24513; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26211064(104844256); length = 3333/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000007_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=35/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000007_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000007_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000008_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/89904.csv:0+5081
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:17 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:17 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:17 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:17 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:17 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:17 INFO streaming.PipeMapRed: Records R/W=13/1
19/03/06 01:00:17 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:17 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:17 INFO mapred.LocalJobRunner: 
19/03/06 01:00:17 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:17 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:17 INFO mapred.MapTask: bufstart = 0; bufend = 12124; bufvoid = 104857600
19/03/06 01:00:17 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212920(104851680); length = 1477/6553600
19/03/06 01:00:17 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:17 INFO mapred.Task: Task:attempt_local860817634_0001_m_000008_0 is done. And is in the process of committing
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Records R/W=13/1
19/03/06 01:00:17 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000008_0' done.
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000008_0
19/03/06 01:00:17 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_m_000009_0
19/03/06 01:00:17 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:17 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:17 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:17 INFO mapred.MapTask: Processing split: file:/tmp/87234.csv:0+4490
19/03/06 01:00:17 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:18 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:18 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:18 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:18 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:18 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:18 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:18 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper1.py]
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO mapreduce.Job: Job job_local860817634_0001 running in uber mode : false
19/03/06 01:00:18 INFO mapreduce.Job:  map 100% reduce 0%
19/03/06 01:00:18 INFO streaming.PipeMapRed: Records R/W=3/1
19/03/06 01:00:18 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:18 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:18 INFO mapred.LocalJobRunner: 
19/03/06 01:00:18 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:18 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:18 INFO mapred.MapTask: bufstart = 0; bufend = 11322; bufvoid = 104857600
19/03/06 01:00:18 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212964(104851856); length = 1433/6553600
19/03/06 01:00:18 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:18 INFO mapred.Task: Task:attempt_local860817634_0001_m_000009_0 is done. And is in the process of committing
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Records R/W=3/1
19/03/06 01:00:18 INFO mapred.Task: Task 'attempt_local860817634_0001_m_000009_0' done.
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_m_000009_0
19/03/06 01:00:18 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Starting task: attempt_local860817634_0001_r_000000_0
19/03/06 01:00:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:18 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:18 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@722985b0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 01:00:18 INFO reduce.EventFetcher: attempt_local860817634_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000007_0 decomp: 26183 len: 26187 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 26183 bytes from map-output for attempt_local860817634_0001_m_000007_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 26183, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->26183
19/03/06 01:00:18 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000001_0 decomp: 121591 len: 121595 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 121591 bytes from map-output for attempt_local860817634_0001_m_000001_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 121591, inMemoryMapOutputs.size() -> 2, commitMemory -> 26183, usedMemory ->147774
19/03/06 01:00:18 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000004_0 decomp: 38909 len: 38913 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 38909 bytes from map-output for attempt_local860817634_0001_m_000004_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38909, inMemoryMapOutputs.size() -> 3, commitMemory -> 147774, usedMemory ->186683
19/03/06 01:00:18 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000005_0 decomp: 38683 len: 38687 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 38683 bytes from map-output for attempt_local860817634_0001_m_000005_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38683, inMemoryMapOutputs.size() -> 4, commitMemory -> 186683, usedMemory ->225366
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000008_0 decomp: 12866 len: 12870 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 12866 bytes from map-output for attempt_local860817634_0001_m_000008_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12866, inMemoryMapOutputs.size() -> 5, commitMemory -> 225366, usedMemory ->238232
19/03/06 01:00:18 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000002_0 decomp: 70114 len: 70118 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 70114 bytes from map-output for attempt_local860817634_0001_m_000002_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70114, inMemoryMapOutputs.size() -> 6, commitMemory -> 238232, usedMemory ->308346
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000009_0 decomp: 12046 len: 12050 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 12046 bytes from map-output for attempt_local860817634_0001_m_000009_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12046, inMemoryMapOutputs.size() -> 7, commitMemory -> 308346, usedMemory ->320392
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000003_0 decomp: 50851 len: 50855 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 50851 bytes from map-output for attempt_local860817634_0001_m_000003_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 50851, inMemoryMapOutputs.size() -> 8, commitMemory -> 320392, usedMemory ->371243
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000006_0 decomp: 29326 len: 29330 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 29326 bytes from map-output for attempt_local860817634_0001_m_000006_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29326, inMemoryMapOutputs.size() -> 9, commitMemory -> 371243, usedMemory ->400569
19/03/06 01:00:18 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local860817634_0001_m_000000_0 decomp: 122333 len: 122337 to MEMORY
19/03/06 01:00:18 INFO reduce.InMemoryMapOutput: Read 122333 bytes from map-output for attempt_local860817634_0001_m_000000_0
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122333, inMemoryMapOutputs.size() -> 10, commitMemory -> 400569, usedMemory ->522902
19/03/06 01:00:18 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 01:00:18 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 01:00:18 INFO mapred.Merger: Merging 10 sorted segments
19/03/06 01:00:18 INFO mapred.Merger: Down to the last merge-pass, with 10 segments left of total size: 522623 bytes
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: Merged 10 segments, 522902 bytes to disk to satisfy reduce memory limit
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: Merging 1 files, 522888 bytes from disk
19/03/06 01:00:18 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 01:00:18 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:18 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 522858 bytes
19/03/06 01:00:18 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 01:00:18 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer1.py]
19/03/06 01:00:18 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 01:00:18 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO streaming.PipeMapRed: Records R/W=3865/1
19/03/06 01:00:18 INFO streaming.PipeMapRed: R/W/S=10000/4508/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:18 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:18 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:18 INFO mapred.Task: Task:attempt_local860817634_0001_r_000000_0 is done. And is in the process of committing
19/03/06 01:00:18 INFO mapred.LocalJobRunner: 10 / 10 copied.
19/03/06 01:00:18 INFO mapred.Task: Task attempt_local860817634_0001_r_000000_0 is allowed to commit now
19/03/06 01:00:18 INFO output.FileOutputCommitter: Saved output of task 'attempt_local860817634_0001_r_000000_0' to file:/tmp/mapreduce-output/_temporary/0/task_local860817634_0001_r_000000
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Records R/W=3865/1 > reduce
19/03/06 01:00:18 INFO mapred.Task: Task 'attempt_local860817634_0001_r_000000_0' done.
19/03/06 01:00:18 INFO mapred.LocalJobRunner: Finishing task: attempt_local860817634_0001_r_000000_0
19/03/06 01:00:18 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 01:00:19 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 01:00:19 INFO mapreduce.Job: Job job_local860817634_0001 completed successfully
19/03/06 01:00:19 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=4273573
		FILE: Number of bytes written=12040491
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=433
		Map output records=15462
		Map output bytes=491934
		Map output materialized bytes=522942
		Input split bytes=707
		Combine input records=0
		Combine output records=0
		Reduce input groups=9040
		Reduce shuffle bytes=522942
		Reduce input records=15462
		Reduce output records=9040
		Spilled Records=30924
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=95
		Total committed heap usage (bytes)=4099932160
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=199538
	File Output Format Counters 
		Bytes Written=305965
19/03/06 01:00:19 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output/part-00000 -output /tmp/mapreduce-output2 -mapper /usr/lib/mapreduce/mapper2.py -reducer /usr/lib/mapreduce/reducer2.py
19/03/06 01:00:25 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 01:00:25 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 01:00:25 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 01:00:25 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 01:00:25 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 01:00:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local830599458_0001
19/03/06 01:00:26 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 01:00:26 INFO mapreduce.Job: Running job: job_local830599458_0001
19/03/06 01:00:26 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 01:00:26 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 01:00:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:26 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Starting task: attempt_local830599458_0001_m_000000_0
19/03/06 01:00:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:26 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:26 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:26 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output/part-00000:0+303585
19/03/06 01:00:26 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:26 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:26 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:26 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:26 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:26 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:26 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:26 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper2.py]
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 01:00:26 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 01:00:26 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 01:00:26 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 01:00:26 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: Records R/W=3840/1
19/03/06 01:00:26 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:26 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:26 INFO mapred.LocalJobRunner: 
19/03/06 01:00:26 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:26 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:26 INFO mapred.MapTask: bufstart = 0; bufend = 303595; bufvoid = 104857600
19/03/06 01:00:26 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26178240(104712960); length = 36157/6553600
19/03/06 01:00:26 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:26 INFO mapred.Task: Task:attempt_local830599458_0001_m_000000_0 is done. And is in the process of committing
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Records R/W=3840/1
19/03/06 01:00:26 INFO mapred.Task: Task 'attempt_local830599458_0001_m_000000_0' done.
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Finishing task: attempt_local830599458_0001_m_000000_0
19/03/06 01:00:26 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Starting task: attempt_local830599458_0001_r_000000_0
19/03/06 01:00:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:26 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:26 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:26 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ffd1663
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 01:00:26 INFO reduce.EventFetcher: attempt_local830599458_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 01:00:26 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local830599458_0001_m_000000_0 decomp: 321687 len: 321691 to MEMORY
19/03/06 01:00:26 INFO reduce.InMemoryMapOutput: Read 321687 bytes from map-output for attempt_local830599458_0001_m_000000_0
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 321687, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->321687
19/03/06 01:00:26 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 01:00:26 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 01:00:26 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:26 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:26 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 321665 bytes
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: Merged 1 segments, 321687 bytes to disk to satisfy reduce memory limit
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: Merging 1 files, 321691 bytes from disk
19/03/06 01:00:26 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 01:00:26 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:26 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 321665 bytes
19/03/06 01:00:26 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:26 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer2.py]
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 01:00:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:26 INFO streaming.PipeMapRed: Records R/W=9040/1
19/03/06 01:00:26 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:26 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:26 INFO mapred.Task: Task:attempt_local830599458_0001_r_000000_0 is done. And is in the process of committing
19/03/06 01:00:26 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:26 INFO mapred.Task: Task attempt_local830599458_0001_r_000000_0 is allowed to commit now
19/03/06 01:00:26 INFO output.FileOutputCommitter: Saved output of task 'attempt_local830599458_0001_r_000000_0' to file:/tmp/mapreduce-output2/_temporary/0/task_local830599458_0001_r_000000
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Records R/W=9040/1 > reduce
19/03/06 01:00:26 INFO mapred.Task: Task 'attempt_local830599458_0001_r_000000_0' done.
19/03/06 01:00:26 INFO mapred.LocalJobRunner: Finishing task: attempt_local830599458_0001_r_000000_0
19/03/06 01:00:26 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 01:00:27 INFO mapreduce.Job: Job job_local830599458_0001 running in uber mode : false
19/03/06 01:00:27 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 01:00:27 INFO mapreduce.Job: Job job_local830599458_0001 completed successfully
19/03/06 01:00:27 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1525896
		FILE: Number of bytes written=2547695
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9040
		Map output records=9040
		Map output bytes=303595
		Map output materialized bytes=321691
		Input split bytes=89
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=321691
		Reduce input records=9040
		Reduce output records=9040
		Spilled Records=18080
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=305969
	File Output Format Counters 
		Bytes Written=349942
19/03/06 01:00:27 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output2
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output2/part-00000 -output /tmp/mapreduce-output3 -mapper /usr/lib/mapreduce/mapper3.py -reducer /usr/lib/mapreduce/reducer3.py
19/03/06 01:00:31 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 01:00:31 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 01:00:31 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 01:00:31 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 01:00:31 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 01:00:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1950462360_0001
19/03/06 01:00:31 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 01:00:31 INFO mapreduce.Job: Running job: job_local1950462360_0001
19/03/06 01:00:31 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 01:00:31 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 01:00:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:31 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 01:00:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1950462360_0001_m_000000_0
19/03/06 01:00:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:31 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output2/part-00000:0+347218
19/03/06 01:00:31 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:31 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:31 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper3.py]
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 01:00:31 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 01:00:31 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 01:00:31 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 01:00:31 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 01:00:31 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 01:00:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:31 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:31 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:31 INFO streaming.PipeMapRed: Records R/W=3353/1
19/03/06 01:00:32 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:32 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:32 INFO mapred.LocalJobRunner: 
19/03/06 01:00:32 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:32 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:32 INFO mapred.MapTask: bufstart = 0; bufend = 365306; bufvoid = 104857600
19/03/06 01:00:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26178240(104712960); length = 36157/6553600
19/03/06 01:00:32 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:32 INFO mapred.Task: Task:attempt_local1950462360_0001_m_000000_0 is done. And is in the process of committing
19/03/06 01:00:32 INFO mapred.LocalJobRunner: Records R/W=3353/1
19/03/06 01:00:32 INFO mapred.Task: Task 'attempt_local1950462360_0001_m_000000_0' done.
19/03/06 01:00:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950462360_0001_m_000000_0
19/03/06 01:00:32 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 01:00:32 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 01:00:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1950462360_0001_r_000000_0
19/03/06 01:00:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:32 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1163e715
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 01:00:32 INFO reduce.EventFetcher: attempt_local1950462360_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 01:00:32 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950462360_0001_m_000000_0 decomp: 383397 len: 383401 to MEMORY
19/03/06 01:00:32 INFO reduce.InMemoryMapOutput: Read 383397 bytes from map-output for attempt_local1950462360_0001_m_000000_0
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 383397, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->383397
19/03/06 01:00:32 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 01:00:32 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 01:00:32 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
19/03/06 01:00:32 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:32 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 383391 bytes
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: Merged 1 segments, 383397 bytes to disk to satisfy reduce memory limit
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: Merging 1 files, 383401 bytes from disk
19/03/06 01:00:32 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 01:00:32 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:32 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 383391 bytes
19/03/06 01:00:32 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:32 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/reducer3.py]
19/03/06 01:00:32 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
19/03/06 01:00:32 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/03/06 01:00:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:32 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:32 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:32 INFO streaming.PipeMapRed: Records R/W=9040/1
19/03/06 01:00:32 INFO mapreduce.Job: Job job_local1950462360_0001 running in uber mode : false
19/03/06 01:00:32 INFO mapreduce.Job:  map 100% reduce 0%
19/03/06 01:00:34 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:34 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:34 INFO mapred.Task: Task:attempt_local1950462360_0001_r_000000_0 is done. And is in the process of committing
19/03/06 01:00:34 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:34 INFO mapred.Task: Task attempt_local1950462360_0001_r_000000_0 is allowed to commit now
19/03/06 01:00:34 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1950462360_0001_r_000000_0' to file:/tmp/mapreduce-output3/_temporary/0/task_local1950462360_0001_r_000000
19/03/06 01:00:34 INFO mapred.LocalJobRunner: Records R/W=9040/1 > reduce
19/03/06 01:00:34 INFO mapred.Task: Task 'attempt_local1950462360_0001_r_000000_0' done.
19/03/06 01:00:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950462360_0001_r_000000_0
19/03/06 01:00:34 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 01:00:35 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 01:00:35 INFO mapreduce.Job: Job job_local1950462360_0001 completed successfully
19/03/06 01:00:35 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1737272
		FILE: Number of bytes written=2654015
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=9040
		Map output records=9040
		Map output bytes=365306
		Map output materialized bytes=383401
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6215
		Reduce shuffle bytes=383401
		Reduce input records=9040
		Reduce output records=6215
		Spilled Records=18080
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349946
	File Output Format Counters 
		Bytes Written=266522
19/03/06 01:00:35 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output3
vagrant@ubuntu-xenial:/tmp$ hadoop jar /usr/local/hadoop/share/doc/hadoop/api/org/apache/hadoop/contrib/hadoop-streaming-2.9.0.jar -input /tmp/mapreduce-output3/part-00000 -output /tmp/mapreduce-output4 -mapper /usr/lib/mapreduce/mapper4.py
19/03/06 01:00:39 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/03/06 01:00:39 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/03/06 01:00:39 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
19/03/06 01:00:39 INFO mapred.FileInputFormat: Total input files to process : 1
19/03/06 01:00:39 INFO mapreduce.JobSubmitter: number of splits:1
19/03/06 01:00:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local222637146_0001
19/03/06 01:00:39 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
19/03/06 01:00:39 INFO mapreduce.Job: Running job: job_local222637146_0001
19/03/06 01:00:39 INFO mapred.LocalJobRunner: OutputCommitter set in config null
19/03/06 01:00:39 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
19/03/06 01:00:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:39 INFO mapred.LocalJobRunner: Waiting for map tasks
19/03/06 01:00:39 INFO mapred.LocalJobRunner: Starting task: attempt_local222637146_0001_m_000000_0
19/03/06 01:00:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:39 INFO mapred.MapTask: Processing split: file:/tmp/mapreduce-output3/part-00000:0+264446
19/03/06 01:00:39 INFO mapred.MapTask: numReduceTasks: 1
19/03/06 01:00:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
19/03/06 01:00:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
19/03/06 01:00:39 INFO mapred.MapTask: soft limit at 83886080
19/03/06 01:00:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
19/03/06 01:00:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
19/03/06 01:00:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
19/03/06 01:00:39 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/lib/mapreduce/mapper4.py]
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
19/03/06 01:00:39 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
19/03/06 01:00:39 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
19/03/06 01:00:39 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
19/03/06 01:00:39 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
19/03/06 01:00:39 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
19/03/06 01:00:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:39 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:39 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]
19/03/06 01:00:39 INFO streaming.PipeMapRed: Records R/W=3093/1
19/03/06 01:00:39 INFO streaming.PipeMapRed: MRErrorThread done
19/03/06 01:00:39 INFO streaming.PipeMapRed: mapRedFinished
19/03/06 01:00:39 INFO mapred.LocalJobRunner: 
19/03/06 01:00:39 INFO mapred.MapTask: Starting flush of map output
19/03/06 01:00:39 INFO mapred.MapTask: Spilling map output
19/03/06 01:00:39 INFO mapred.MapTask: bufstart = 0; bufend = 319847; bufvoid = 104857600
19/03/06 01:00:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26189540(104758160); length = 24857/6553600
19/03/06 01:00:40 INFO mapred.MapTask: Finished spill 0
19/03/06 01:00:40 INFO mapred.Task: Task:attempt_local222637146_0001_m_000000_0 is done. And is in the process of committing
19/03/06 01:00:40 INFO mapred.LocalJobRunner: Records R/W=3093/1
19/03/06 01:00:40 INFO mapred.Task: Task 'attempt_local222637146_0001_m_000000_0' done.
19/03/06 01:00:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local222637146_0001_m_000000_0
19/03/06 01:00:40 INFO mapred.LocalJobRunner: map task executor complete.
19/03/06 01:00:40 INFO mapred.LocalJobRunner: Waiting for reduce tasks
19/03/06 01:00:40 INFO mapred.LocalJobRunner: Starting task: attempt_local222637146_0001_r_000000_0
19/03/06 01:00:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/03/06 01:00:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/03/06 01:00:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
19/03/06 01:00:40 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4662ddc8
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
19/03/06 01:00:40 INFO reduce.EventFetcher: attempt_local222637146_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
19/03/06 01:00:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local222637146_0001_m_000000_0 decomp: 332303 len: 332307 to MEMORY
19/03/06 01:00:40 INFO reduce.InMemoryMapOutput: Read 332303 bytes from map-output for attempt_local222637146_0001_m_000000_0
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 332303, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->332303
19/03/06 01:00:40 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
19/03/06 01:00:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
19/03/06 01:00:40 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:40 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 332277 bytes
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: Merged 1 segments, 332303 bytes to disk to satisfy reduce memory limit
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: Merging 1 files, 332307 bytes from disk
19/03/06 01:00:40 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
19/03/06 01:00:40 INFO mapred.Merger: Merging 1 sorted segments
19/03/06 01:00:40 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 332277 bytes
19/03/06 01:00:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:40 INFO mapred.Task: Task:attempt_local222637146_0001_r_000000_0 is done. And is in the process of committing
19/03/06 01:00:40 INFO mapred.LocalJobRunner: 1 / 1 copied.
19/03/06 01:00:40 INFO mapred.Task: Task attempt_local222637146_0001_r_000000_0 is allowed to commit now
19/03/06 01:00:40 INFO output.FileOutputCommitter: Saved output of task 'attempt_local222637146_0001_r_000000_0' to file:/tmp/mapreduce-output4/_temporary/0/task_local222637146_0001_r_000000
19/03/06 01:00:40 INFO mapred.LocalJobRunner: reduce > reduce
19/03/06 01:00:40 INFO mapred.Task: Task 'attempt_local222637146_0001_r_000000_0' done.
19/03/06 01:00:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local222637146_0001_r_000000_0
19/03/06 01:00:40 INFO mapred.LocalJobRunner: reduce task executor complete.
19/03/06 01:00:40 INFO mapreduce.Job: Job job_local222637146_0001 running in uber mode : false
19/03/06 01:00:40 INFO mapreduce.Job:  map 100% reduce 100%
19/03/06 01:00:40 INFO mapreduce.Job: Job job_local222637146_0001 completed successfully
19/03/06 01:00:40 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=1468244
		FILE: Number of bytes written=2548421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6215
		Map output records=6215
		Map output bytes=319847
		Map output materialized bytes=332307
		Input split bytes=90
		Combine input records=0
		Combine output records=0
		Reduce input groups=6215
		Reduce shuffle bytes=332307
		Reduce input records=6215
		Reduce output records=6215
		Spilled Records=12430
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=266526
	File Output Format Counters 
		Bytes Written=322334
19/03/06 01:00:40 INFO streaming.StreamJob: Output directory: /tmp/mapreduce-output4
vagrant@ubuntu-xenial:/tmp$ cd mapreduce-output4
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ ls
part-00000  _SUCCESS
vagrant@ubuntu-xenial:/tmp/mapreduce-output4$ nano part-00000 


